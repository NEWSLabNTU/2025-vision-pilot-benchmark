---
# Compile ONNX models to TensorRT engines
# NOTE: The autoware-pov TensorRT backend now supports dynamic batch dimensions
#       automatically, so no ONNX model patching is required.
#       The compilation script uses optimization profiles to handle dynamic inputs.
- name: Compile ONNX models to TensorRT engines
  hosts: localhost
  become: no
  vars:
    project_root: "{{ playbook_dir }}/.."
    models_dir: "{{ project_root }}/models"
    scripts_dir: "{{ project_root }}/scripts"

  tasks:
    - name: Detect platform (Jetson check)
      stat:
        path: /proc/device-tree/model
      register: jetson_model_file

    - name: Set platform facts
      set_fact:
        is_jetson: "{{ jetson_model_file.stat.exists }}"
        is_ubuntu_x86: "{{ ansible_architecture == 'x86_64' and ansible_distribution == 'Ubuntu' and not jetson_model_file.stat.exists }}"
        tensorrt_bin_path: "{{ '/usr/src/tensorrt/bin' if jetson_model_file.stat.exists else '/usr/bin' }}"

    - name: Check if TensorRT is available
      command: "{{ tensorrt_bin_path }}/trtexec --help"
      register: tensorrt_check
      failed_when: false
      changed_when: false

    - name: Skip TensorRT compilation if not available
      meta: end_play
      when: tensorrt_check.rc != 0

    - name: Display TensorRT availability
      debug:
        msg: "TensorRT detected - proceeding with engine compilation"


    - name: Check available ONNX models
      find:
        paths: "{{ models_dir }}"
        patterns: "*.onnx"
      register: onnx_models

    - name: Display available models
      debug:
        msg: "Found {{ onnx_models.files | length }} ONNX models to compile"

    - name: Compile ONNX models to TensorRT engines (FP16)
      command: "python3 {{ scripts_dir }}/compile_tensorrt_engines.py --precision fp16 --models-dir {{ models_dir }}"
      environment:
        PATH: "{{ tensorrt_bin_path }}:{{ ansible_env.PATH }}"
      register: compilation_result
      failed_when: false
      become: no

    - name: Display compilation results
      debug:
        msg: "{{ compilation_result.stdout_lines }}"

    - name: Check compiled engines
      find:
        paths: "{{ models_dir }}"
        patterns: "*.engine"
      register: engine_files

    - name: Display engine summary
      debug:
        msg: |
          TensorRT compilation summary:
          - ONNX models: {{ onnx_models.files | length }}
          - Compiled engines: {{ engine_files.files | length }}
          {% if engine_files.files | length > 0 %}
          Engine files:
          {% for engine in engine_files.files %}
          - {{ engine.path | basename }}
          {% endfor %}
          {% endif %}